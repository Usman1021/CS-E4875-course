{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "### <span style=\"color:red;\">This notebook provides an experimental overview of a face anti-spoofing project based on the Swin Transformer, which was introduced in the paper *Swin Transformer: Hierarchical Vision Transformer using Shifted Windows* by Liu et al.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoImageProcessor, SwinForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Import Visual transformer model from https://huggingface.co/microsoft/swin-tiny-patch4-window7-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "model = SwinForImageClassification.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)                  # Set the seed for Python's built-in random module\n",
    "    np.random.seed(seed)               # Set the seed for NumPy\n",
    "    torch.manual_seed(seed)            # Set the seed for PyTorch CPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)  # Set the seed for all GPUs (if using multiple GPUs)\n",
    "    torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False      # Disable benchmark mode\n",
    "\n",
    "# Call the function with your chosen seed\n",
    "set_seed(42)  # You can choose any seed value\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "# Define data transforms with normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),             # Resize images to a consistent size\n",
    "    transforms.ToTensor(),                     # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize with ImageNet mean and std\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define paths to your data folders\n",
    "train_data_dir = '/u/45/demo_file/long/train/'\n",
    "val_data_dir = '/u/45/demo_file/long/validations/'\n",
    "test_data_dir = '/u/45/demo_file/long/test/'\n",
    "\n",
    "# Load your training, validation, and test datasets using ImageFolder\n",
    "train_dataset = ImageFolder(root=train_data_dir, transform=transform)\n",
    "val_dataset = ImageFolder(root=val_data_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_data_dir, transform=transform)\n",
    "\n",
    "# If you want to access the labels for train, validation, and test datasets:\n",
    "train_labels = train_dataset.targets\n",
    "val_labels = val_dataset.targets\n",
    "test_labels = test_dataset.targets\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 8  # Adjust the batch size as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print number of images and classes\n",
    "num_train_images = len(train_dataset)\n",
    "num_val_images = len(val_dataset)\n",
    "num_test_images = len(test_dataset)\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "print(f\"Number of training images: {num_train_images}\")\n",
    "print(f\"Number of validation images: {num_val_images}\")\n",
    "print(f\"Number of test images: {num_test_images}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {train_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a binary classification head\n",
    "class BinaryClassificationHead(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(BinaryClassificationHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Modify the Swin Transformer model for binary classification\n",
    "classifier_head = BinaryClassificationHead(768, 32)  # Adjust input size as needed\n",
    "model.classifier = classifier_head\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming model, train_loader, val_loader, test_loader, criterion, and optimizer are defined\n",
    "\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Initialize early stopping parameters\n",
    "patience = 2\n",
    "verbose = True\n",
    "delta = 0.001  # For validation loss improvements\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "best_eer_threshold = 0.5  # Placeholder for the EER threshold from the validation set\n",
    "\n",
    "# Initialize lists to store training and validation losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    for data, labels in train_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data).logits  # Get logits from model\n",
    "        loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_labels = []  # Store true labels\n",
    "    val_scores = []  # To store probabilities for EER calculation\n",
    "    with torch.no_grad():\n",
    "        for val_data, val_labels_batch in val_loader:\n",
    "            val_data, val_labels_batch = val_data.to(device), val_labels_batch.to(device)\n",
    "            val_outputs = model(val_data).logits\n",
    "            val_loss += criterion(val_outputs, val_labels_batch.unsqueeze(1).float()).item()\n",
    "            \n",
    "            # Get probabilities (sigmoid for binary classification)\n",
    "            val_probs = torch.sigmoid(val_outputs).cpu().numpy()  # Convert logits to probabilities\n",
    "            val_scores.extend(val_probs)\n",
    "            val_labels.extend(val_labels_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate average training and validation loss\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # EER Calculation on validation set\n",
    "    fpr, tpr, thresholds = roc_curve(val_labels, val_scores, pos_label=1)  # Ensure pos_label is set\n",
    "    fnr = 1 - tpr  # Calculate False Negative Rate\n",
    "    eer_threshold_idx = np.nanargmin(np.abs(fnr - fpr))  # Find index where FNR == FPR\n",
    "    eer_threshold = thresholds[eer_threshold_idx]  # EER threshold\n",
    "    eer_fpr = fpr[eer_threshold_idx]\n",
    "    eer_fnr = fnr[eer_threshold_idx]\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, EER: {eer_fpr:.4f}, EER Threshold: {eer_threshold:.4f}\")\n",
    "\n",
    "    # Early stopping based on validation loss\n",
    "    if avg_val_loss < best_val_loss - delta:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_eer_threshold = eer_threshold  # Save the EER threshold for the test set\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            if verbose:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Append losses for plotting\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(val_losses, label='Validation Loss', color='orange')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(fpr, tpr, label='ROC Curve', color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate (FAR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training completed and best EER threshold saved from validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming best_eer_threshold is defined based on validation results\n",
    "\n",
    "# --- Now calculate HTER on the test set using the EER threshold from validation ---\n",
    "test_labels = []\n",
    "test_scores = []\n",
    "\n",
    "# Step 1: Gather predictions on the test set\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(inputs)  # Model outputs\n",
    "        scores = torch.sigmoid(outputs.logits).cpu().numpy()  # Compute probabilities\n",
    "\n",
    "        test_labels.extend(labels.cpu().numpy())  # Collect true labels\n",
    "        test_scores.extend(scores)  # Collect predicted scores (probabilities)\n",
    "\n",
    "# Step 2: Initialize counters for FAR and FRR\n",
    "false_accepts = 0  # Counter for false accepts (impostor samples classified as genuine)\n",
    "false_rejects = 0  # Counter for false rejects (genuine samples classified as impostors)\n",
    "total_genuine = 0  # Counter for total genuine samples\n",
    "total_impostors = 0  # Counter for total impostor samples\n",
    "\n",
    "# Step 3: Classify test set based on the EER threshold\n",
    "for label, score in zip(test_labels, test_scores):\n",
    "    if label == 0:  # Genuine sample\n",
    "        total_genuine += 1\n",
    "        if score >= best_eer_threshold:  # False rejection (genuine classified as impostor)\n",
    "            false_rejects += 1\n",
    "    else:  # Impostor sample\n",
    "        total_impostors += 1\n",
    "        if score < best_eer_threshold:  # False acceptance (impostor classified as genuine)\n",
    "            false_accepts += 1\n",
    "\n",
    "# Step 4: Calculate FAR and FRR while avoiding division by zero\n",
    "far = false_accepts / total_impostors if total_impostors > 0 else 0  # False Acceptance Rate\n",
    "frr = false_rejects / total_genuine if total_genuine > 0 else 0  # False Rejection Rate\n",
    "\n",
    "# Step 5: Calculate HTER on the test set\n",
    "hter = (far + frr) / 2  # Half Total Error Rate\n",
    "\n",
    "# Output the results\n",
    "print(f\"Half Total Error Rate (HTER) on test set using EER threshold: {hter * 100:.2f}%\")\n",
    "\n",
    "# Step 6: Calculate AUC on test set\n",
    "auc = roc_auc_score(test_labels, test_scores)\n",
    "print(f\"Area Under the ROC Curve (AUC) on test set: {auc * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "pt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
